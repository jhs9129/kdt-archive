{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 프레임 수: 881\n",
      "얼굴 랜드마크가 검출된 총 프레임 수: 751\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import mysql.connector  \n",
    "# import pymysql\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "def download_video_from_s3(bucket_name, video_name, local_path):\n",
    "    s3 = boto3.client('s3', aws_access_key_id = os.environ.get(\"AWS_ACCESS_KEY_ID\"), aws_secret_access_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "\n",
    "    try:\n",
    "        s3.download_file(bucket_name, f\"{video_name}.mp4\", local_path)\n",
    "        print(f\"Video downloaded from S3 to {local_path}\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "\n",
    "def insert_data_to_rds(json_file_path):\n",
    "    # RDS 연결 설정\n",
    "    connection = mysql.connector.connect(\n",
    "        host = os.environ.get(\"USER_HOST\"),\n",
    "        user = os.environ.get(\"USER_ID\"),\n",
    "        password = os.environ.get(\"USER_PASSWORD\"),\n",
    "        database = os.environ.get(\"USER_DB\")\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # RDS 테이블에 데이터 삽입\n",
    "    insert_query = \"INSERT INTO USER_FM (tot_frame, detect_frame, proba, no_proba, name) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    insert_data = (data[\"Total_Frame\"], data[\"Detection_Frame\"], data[\"Probability\"], data[\"No_Probability\"], data[\"Video_Name\"])\n",
    "\n",
    "    cursor.execute(insert_query, insert_data)\n",
    "    connection.commit()\n",
    "\n",
    "    # 연결 닫기\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "def process_video(video_name):\n",
    "    # S3에서 동영상 다운로드\n",
    "    bucket_name = '3-example-video'\n",
    "    local_video_path = f\"./{video_name}.mp4\"\n",
    "    download_video_from_s3(bucket_name, video_name, local_video_path)\n",
    "\n",
    "    # 동영상 파일 열기\n",
    "    cap = cv2.VideoCapture(local_video_path)\n",
    "\n",
    "    # 총 프레임 수 \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 동영상이 정상적으로 열렸는지 확인\n",
    "    if not cap.isOpened():\n",
    "        print(f\"비디오 파일을 찾을 수 없습니다: {local_video_path}\")\n",
    "        return\n",
    "\n",
    "    # mediapipe FaceMesh 인스턴스 생성\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, \n",
    "                               max_num_faces=1,    \n",
    "                               refine_landmarks=True,   \n",
    "                               min_detection_confidence=0.5,\n",
    "                               min_tracking_confidence=0.85) as face_mesh:\n",
    "\n",
    "        frame_count_with_landmarks = 0\n",
    "\n",
    "        # 동영상 프레임을 순회하며 처리\n",
    "        while cap.isOpened():\n",
    "            # 동영상에서 프레임 읽기\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # BGR을 RGB로 변환\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 얼굴 랜드마크 검출\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "\n",
    "            # 얼굴 랜드마크를 프레임에 표시\n",
    "            if results.multi_face_landmarks:\n",
    "                frame_count_with_landmarks += 1\n",
    "\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image=frame, \n",
    "                                              landmark_list=face_landmarks, \n",
    "                                              connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                              landmark_drawing_spec=drawing_spec, \n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                              landmark_drawing_spec=drawing_spec,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                                              landmark_drawing_spec=None,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "        # 처리가 끝나면 리소스 해제\n",
    "        cap.release()\n",
    "\n",
    "    Detection = frame_count_with_landmarks / total_frames\n",
    "    N_Detection = 1 - Detection\n",
    "\n",
    "    # 결과 데이터 추가\n",
    "    data = {\n",
    "        \"Total_Frame\": total_frames,\n",
    "        \"Detection_Frame\": frame_count_with_landmarks,\n",
    "        \"Probability\": Detection,\n",
    "        \"No_Probability\": N_Detection,\n",
    "        \"Video_Name\": video_name\n",
    "    }\n",
    "\n",
    "    # 결과 데이터 저장\n",
    "    with open(f\"{video_name}.json\", 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    try:\n",
    "        print(\"rds 전\")\n",
    "        # RDS에 데이터 삽입\n",
    "        insert_data_to_rds(f\"{video_name}.json\")\n",
    "    except Exception as e:\n",
    "        print(\"error occurred: \", str(e))\n",
    "    # 끝\n",
    "    print(\"데이터 삽입이 완료되었습니다.\")\n",
    "\n",
    "def get_latest_video_name(bucket_name):\n",
    "    s3 = boto3.client('s3', aws_access_key_id = os.environ.get(\"AWS_ACCESS_KEY_ID\"), aws_secret_access_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "\n",
    "    # S3 버킷 내에서 객체 목록을 가져옴\n",
    "    response = s3.list_objects(Bucket=bucket_name)\n",
    "\n",
    "    # 가장 최근에 업로드된 객체 선택\n",
    "    latest_object = max(response['Contents'], key=lambda x: x['LastModified'])\n",
    "\n",
    "    # 파일 이름 반환 (확장자 제외)\n",
    "    latest_video_name = os.path.splitext(os.path.basename(latest_object['Key']))[0]\n",
    "\n",
    "    return latest_video_name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # S3 버킷 이름\n",
    "    print(\"os.environ: \", os.environ)\n",
    "    s3_bucket_name = '3-example-video'\n",
    "\n",
    "    # 최근에 업로드된 동영상 이름 가져오기\n",
    "    latest_video_name = get_latest_video_name(s3_bucket_name)\n",
    "\n",
    "    # 동영상 처리 함수 호출\n",
    "    process_video(latest_video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 프레임 수: 881\n",
      "얼굴 랜드마크가 검출된 총 프레임 수: 707\n"
     ]
    }
   ],
   "source": [
    "# json파일 부분 수정\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# 동영상 파일 경로\n",
    "video_name = '1'\n",
    "video_path = f\"../../연습강의/{video_name}.mp4\"\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 총 프레임 수 \n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"총 프레임 수: {total_frames}\")\n",
    "\n",
    "# 동영상이 정상적으로 열렸는지 확인\n",
    "if not cap.isOpened():\n",
    "    print(f\"비디오 파일을 찾을 수 없습니다: {video_path}\")\n",
    "\n",
    "# mediapipe FaceMesh 인스턴스 생성\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=False, \n",
    "                           max_num_faces=1,    \n",
    "                           refine_landmarks=True,   \n",
    "                           min_detection_confidence=0.5,\n",
    "                           min_tracking_confidence=0.85) as face_mesh:\n",
    "\n",
    "    frame_count_with_landmarks = 0\n",
    "\n",
    "    # 동영상 프레임을 순회하며 처리\n",
    "    while cap.isOpened():\n",
    "        # 동영상에서 프레임 읽기\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 얼굴 랜드마크 검출\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "\n",
    "        # 얼굴 랜드마크를 프레임에 표시\n",
    "        if results.multi_face_landmarks:\n",
    "            frame_count_with_landmarks += 1\n",
    "\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(image=frame, \n",
    "                                          landmark_list=face_landmarks, \n",
    "                                          connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                          landmark_drawing_spec=drawing_spec, \n",
    "                                          connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "                mp_drawing.draw_landmarks(image=frame,\n",
    "                                          landmark_list=face_landmarks,\n",
    "                                          connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                          landmark_drawing_spec=drawing_spec,\n",
    "                                          connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                mp_drawing.draw_landmarks(image=frame,\n",
    "                                          landmark_list=face_landmarks,\n",
    "                                          connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                                          landmark_drawing_spec=None,\n",
    "                                          connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "    # 처리가 끝나면 리소스 해제\n",
    "    cap.release()\n",
    "\n",
    "Detection = frame_count_with_landmarks / total_frames\n",
    "N_Detection = 1 - Detection\n",
    "\n",
    "\n",
    "# 결과 데이터 추가\n",
    "data = {\n",
    "    \"Total_Frame\": total_frames,\n",
    "    \"Detection_Frame\": frame_count_with_landmarks,\n",
    "    \"Probability\": Detection,\n",
    "    \"No_Probability\": N_Detection\n",
    "}\n",
    "\n",
    "plate_data['data'].append(data)\n",
    "\n",
    "# 결과 데이터 저장\n",
    "with open(f\"{video_name}.json\", 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"얼굴 랜드마크가 검출된 총 프레임 수: {frame_count_with_landmarks}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수로 변경\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "def process_video(video_name):\n",
    "    # 동영상 파일 경로\n",
    "    video_path = f\"../../연습강의/{video_name}.mp4\"\n",
    "\n",
    "    # 동영상 파일 열기\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 총 프레임 수 \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"총 프레임 수: {total_frames}\")\n",
    "\n",
    "    # 동영상이 정상적으로 열렸는지 확인\n",
    "    if not cap.isOpened():\n",
    "        print(f\"비디오 파일을 찾을 수 없습니다: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # mediapipe FaceMesh 인스턴스 생성\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, \n",
    "                               max_num_faces=1,    \n",
    "                               refine_landmarks=True,   \n",
    "                               min_detection_confidence=0.5,\n",
    "                               min_tracking_confidence=0.85) as face_mesh:\n",
    "\n",
    "        frame_count_with_landmarks = 0\n",
    "\n",
    "        # 동영상 프레임을 순회하며 처리\n",
    "        while cap.isOpened():\n",
    "            # 동영상에서 프레임 읽기\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # BGR을 RGB로 변환\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 얼굴 랜드마크 검출\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "\n",
    "            # 얼굴 랜드마크를 프레임에 표시\n",
    "            if results.multi_face_landmarks:\n",
    "                frame_count_with_landmarks += 1\n",
    "\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image=frame, \n",
    "                                              landmark_list=face_landmarks, \n",
    "                                              connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                              landmark_drawing_spec=drawing_spec, \n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                              landmark_drawing_spec=drawing_spec,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                                              landmark_drawing_spec=None,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "        # 처리가 끝나면 리소스 해제\n",
    "        cap.release()\n",
    "\n",
    "    Detection = frame_count_with_landmarks / total_frames\n",
    "    N_Detection = 1 - Detection\n",
    "\n",
    "    # 결과 데이터 추가\n",
    "    data = {\n",
    "        \"Total_Frame\": total_frames,\n",
    "        \"Detection_Frame\": frame_count_with_landmarks,\n",
    "        \"Probability\": Detection,\n",
    "        \"No_Probability\": N_Detection\n",
    "    }\n",
    "\n",
    "    # 결과 데이터 저장\n",
    "    with open(f\"{video_name}.json\", 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"얼굴 랜드마크가 검출된 총 프레임 수: {frame_count_with_landmarks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 프레임 수: 881\n",
      "얼굴 랜드마크가 검출된 총 프레임 수: 751\n"
     ]
    }
   ],
   "source": [
    "process_video(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video downloaded from S3 to ./11.mp4\n",
      "됐따!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "def download_video_from_s3(bucket_name, video_name, local_path):\n",
    "    s3 = boto3.client('s3', aws_access_key_id='', aws_secret_access_key='')\n",
    "\n",
    "    try:\n",
    "        s3.download_file(bucket_name, f\"{video_name}.mp4\", local_path)\n",
    "        print(f\"Video downloaded from S3 to {local_path}\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "\n",
    "def process_video(video_name):\n",
    "    # S3에서 동영상 다운로드\n",
    "    bucket_name = '3-example-video'\n",
    "    local_video_path = f\"./{video_name}.mp4\"\n",
    "    download_video_from_s3(bucket_name, video_name, local_video_path)\n",
    "\n",
    "    # 동영상 파일 열기\n",
    "    cap = cv2.VideoCapture(local_video_path)\n",
    "\n",
    "    # 총 프레임 수 \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 동영상이 정상적으로 열렸는지 확인\n",
    "    if not cap.isOpened():\n",
    "        print(f\"비디오 파일을 찾을 수 없습니다: {local_video_path}\")\n",
    "        return\n",
    "\n",
    "    # mediapipe FaceMesh 인스턴스 생성\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, \n",
    "                               max_num_faces=1,    \n",
    "                               refine_landmarks=True,   \n",
    "                               min_detection_confidence=0.5,\n",
    "                               min_tracking_confidence=0.85) as face_mesh:\n",
    "\n",
    "        frame_count_with_landmarks = 0\n",
    "\n",
    "        # 동영상 프레임을 순회하며 처리\n",
    "        while cap.isOpened():\n",
    "            # 동영상에서 프레임 읽기\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # BGR을 RGB로 변환\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 얼굴 랜드마크 검출\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "\n",
    "            # 얼굴 랜드마크를 프레임에 표시\n",
    "            if results.multi_face_landmarks:\n",
    "                frame_count_with_landmarks += 1\n",
    "\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image=frame, \n",
    "                                              landmark_list=face_landmarks, \n",
    "                                              connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                              landmark_drawing_spec=drawing_spec, \n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                              landmark_drawing_spec=drawing_spec,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                                              landmark_drawing_spec=None,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "        # 처리가 끝나면 리소스 해제\n",
    "        cap.release()\n",
    "\n",
    "    Detection = frame_count_with_landmarks / total_frames\n",
    "    N_Detection = 1 - Detection\n",
    "\n",
    "    # 결과 데이터 추가\n",
    "    data = {\n",
    "        \"Total_Frame\": total_frames,\n",
    "        \"Detection_Frame\": frame_count_with_landmarks,\n",
    "        \"Probability\": Detection,\n",
    "        \"No_Probability\": N_Detection\n",
    "    }\n",
    "\n",
    "    # 결과 데이터 저장\n",
    "    with open(f\"{video_name}.json\", 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "    # 끝\n",
    "    print(\"됐따!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "process_video('11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting numpy>=1.17.0 (from opencv-python)\n",
      "  Downloading numpy-1.26.2-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     --------------------------------- ------ 51.2/61.2 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 61.2/61.2 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/38.1 MB 12.4 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 2.3/38.1 MB 23.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.0/38.1 MB 49.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 7.3/38.1 MB 51.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 7.3/38.1 MB 51.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 7.3/38.1 MB 51.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 7.3/38.1 MB 51.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 8.3/38.1 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.4/38.1 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 16.1/38.1 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.8/38.1 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.3/38.1 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.1/38.1 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.9/38.1 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 65.5 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.2-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.7/15.8 MB 118.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.0/15.8 MB 102.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.3/15.8 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 73.0 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.26.2 opencv-python-4.8.1.78\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.9-cp39-cp39-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.8.2-cp39-cp39-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from mediapipe) (1.26.2)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.4.6-py3-none-win_amd64.whl (199 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.16.0-cp39-cp39-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.2.0-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
      "  Using cached fonttools-4.47.0-cp39-cp39-win_amd64.whl.metadata (160 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from matplotlib->mediapipe) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib->mediapipe)\n",
      "  Using cached importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.9-cp39-cp39-win_amd64.whl (50.5 MB)\n",
      "Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Using cached matplotlib-3.8.2-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "Using cached opencv_contrib_python-4.8.1.78-cp37-abi3-win_amd64.whl (44.8 MB)\n",
      "Using cached cffi-1.16.0-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Using cached contourpy-1.2.0-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.47.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Using cached importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n",
      "Installing collected packages: opencv-contrib-python, kiwisolver, importlib-resources, fonttools, cycler, contourpy, CFFI, attrs, absl-py, sounddevice, matplotlib, mediapipe\n",
      "Successfully installed CFFI-1.16.0 absl-py-2.0.0 attrs-23.1.0 contourpy-1.2.0 cycler-0.12.1 fonttools-4.47.0 importlib-resources-6.1.1 kiwisolver-1.4.5 matplotlib-3.8.2 mediapipe-0.10.9 opencv-contrib-python-4.8.1.78 sounddevice-0.4.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.34.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.5 (from boto3)\n",
      "  Downloading botocore-1.34.5-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.10.0,>=0.9.0 (from boto3)\n",
      "  Downloading s3transfer-0.9.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from botocore<1.35.0,>=1.34.5->boto3) (2.8.2)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.35.0,>=1.34.5->boto3)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.9/48.9 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\feature_fm\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.5->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.5-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.3/139.3 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading botocore-1.34.5-py3-none-any.whl (11.9 MB)\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.8/11.9 MB 119.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.9 MB 98.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.9/11.9 MB 93.8 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.9.0-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.0/82.0 kB ? eta 0:00:00\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.8/143.8 kB 8.3 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.34.5 botocore-1.34.5 jmespath-1.0.1 s3transfer-0.9.0 urllib3-1.26.18\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계\n",
      "MediaPipe version: 0.10.9\n"
     ]
    }
   ],
   "source": [
    "print(\"1단계\")\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "# print(\"MediaPipe FaceMesh model version:\", mp_face_mesh.face_mesh_model_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계\n",
      "MediaPipe version: 0.10.9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "os.environ:  environ({'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Roaming', 'CHROME_CRASHPAD_PIPE_NAME': '\\\\\\\\.\\\\pipe\\\\crashpad_16476_OLXJXISWZKMZITCC', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'DESKTOP-UJRJVA2', 'COMSPEC': 'C:\\\\Windows\\\\system32\\\\cmd.exe', 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData', 'EFC_7936': '1', 'ELECTRON_RUN_AS_NODE': '1', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\JHS', 'IGCCSVC_DB': 'AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA8S8EqCDTQUamf4y+Q/fwPgQAAAACAAAAAAAQZgAAAAEAACAAAABYLobO59sYIcFBPojXTg7anFVphXaY+r/762LUBL6RcwAAAAAOgAAAAAIAACAAAAC9UWhobV98mgIGhpX4ENNjivPu0PWKXpu211MuCHVoyWAAAAAdO9LW6CZuoD2teqXeK60LZ6bnIxjrIojON0mH/PlVyHQWrQYUB2iH8oPaQUW+hg+wX0qapEE2DXk9LD9B9CLkf4mtModXtFY8oC3TsXhH9M0csyC1gtqzIT/Z+GL5e95AAAAAThbVDRIUPcoumouyvIjq6nt9DaFtzb4dzR+8jK1buNeAlmtrdt9qCPYIai/DIT78jMX2Hbv5yV5sIAvRI182aA==', 'JPY_INTERRUPT_EVENT': '1900', 'LOCALAPPDATA': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\DESKTOP-UJRJVA2', 'NUMBER_OF_PROCESSORS': '12', 'ONEDRIVE': 'C:\\\\Users\\\\전혁선\\\\OneDrive', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'OS': 'Windows_NT', 'PATH': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\cv2\\\\../../x64/vc14/bin;c:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311;c:\\\\Users\\\\JHS\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\Scripts;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 186 Stepping 3, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': 'ba03', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\Windows\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules', 'PUBLIC': 'C:\\\\Users\\\\Public', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHONIOENCODING': 'utf-8', 'PYTHONUNBUFFERED': '1', 'SESSIONNAME': 'Console', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\Windows', 'TEMP': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Temp', 'USERDOMAIN': 'DESKTOP-UJRJVA2', 'USERDOMAIN_ROAMINGPROFILE': 'DESKTOP-UJRJVA2', 'USERNAME': 'JHS', 'USERPROFILE': 'C:\\\\Users\\\\JHS', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_CODE_CACHE_PATH': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Roaming\\\\Code\\\\CachedData\\\\0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'VSCODE_CWD': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_IPC_HOOK': '\\\\\\\\.\\\\pipe\\\\955620448293eae12eae853ecf8a5608-1.85.1-main-sock', 'VSCODE_NLS_CONFIG': '{\"locale\":\"ko\",\"osLocale\":\"ko\",\"availableLanguages\":{\"*\":\"ko\"},\"_languagePackId\":\"8c714c23d05db6b414b8ab3c57f99fbe.ko\",\"_translationsConfigFile\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\\\\\\\\tcf.json\",\"_cacheRoot\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\",\"_resolvedLanguagePackCoreLocation\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\\\\\\\\0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2\",\"_corruptedFile\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\\\\\\\\corrupted.info\",\"_languagePackSupport\":true}', 'VSCODE_PID': '16476', 'WINDIR': 'C:\\\\Windows', 'ZES_ENABLE_SYSMAN': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'TPU_ML_PLATFORM': 'Tensorflow', 'TF2_BEHAVIOR': '1'})\n",
      "latest_video_name :  연습2\n",
      "Video downloaded from S3 to ./연습2.mp4\n",
      "download_video_from_s3 끝\n",
      "데이터 추출 전\n",
      "된건가\n",
      "json파일 생성\n",
      "rds 전\n",
      "RDS 환경변수 설정 끝\n",
      "insert_data_to_rds 끝\n",
      "데이터 삽입이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import mysql.connector  \n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "print(\"1단계\")\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "\n",
    "def download_video_from_s3(bucket_name, video_name, local_path):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=\"\", aws_secret_access_key=\"\")\n",
    "\n",
    "    try:\n",
    "        s3.download_file(bucket_name, f\"{video_name}.mp4\", local_path)\n",
    "        print(f\"Video downloaded from S3 to {local_path}\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "    \n",
    "    print(\"download_video_from_s3 끝\")\n",
    "print(1)\n",
    "def insert_data_to_rds(json_file_path):\n",
    "    # RDS 연결 설정\n",
    "    connection = mysql.connector.connect(\n",
    "        host='kdt4-bd-database-team3.c1oby0nabaqs.ap-northeast-2.rds.amazonaws.com',\n",
    "        user='developer_team3',\n",
    "        password='devteam3!',\n",
    "        database='team3'\n",
    "    )\n",
    "    print(\"RDS 환경변수 설정 끝\")\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # RDS 테이블에 데이터 삽입\n",
    "    insert_query = \"INSERT INTO USER_FM (tot_frame, detect_frame, proba, no_proba, name) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    insert_data = (data[\"Total_Frame\"], data[\"Detection_Frame\"], data[\"Probability\"], data[\"No_Probability\"], data[\"Video_Name\"])\n",
    "\n",
    "    cursor.execute(insert_query, insert_data)\n",
    "    connection.commit()\n",
    "\n",
    "    # 연결 닫기\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    print(\"insert_data_to_rds 끝\")\n",
    "print(2)\n",
    "def process_video(video_name):\n",
    "    # S3에서 동영상 다운로드\n",
    "    bucket_name = '3-example-video'\n",
    "    local_video_path = f\"./{video_name}.mp4\"\n",
    "    download_video_from_s3(bucket_name, video_name, local_video_path)\n",
    "\n",
    "    # 동영상 파일 열기\n",
    "    cap = cv2.VideoCapture(local_video_path)\n",
    "\n",
    "    # 총 프레임 수 \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 동영상이 정상적으로 열렸는지 확인\n",
    "    if not cap.isOpened():\n",
    "        print(f\"비디오 파일을 찾을 수 없습니다: {local_video_path}\")\n",
    "        return\n",
    "\n",
    "    print(\"데이터 추출 전\")   # 여기까지 무조건 됨\n",
    "    # mediapipe FaceMesh 인스턴스 생성\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, \n",
    "                               max_num_faces=1,    \n",
    "                               refine_landmarks=True,   \n",
    "                               min_detection_confidence=0.5,\n",
    "                               min_tracking_confidence=0.85) as face_mesh: \n",
    "        frame_count_with_landmarks = 0\n",
    "        print(\"된건가\")\n",
    "        # 동영상 프레임을 순회하며 처리\n",
    "        while cap.isOpened():\n",
    "            # 동영상에서 프레임 읽기\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # BGR을 RGB로 변환\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 얼굴 랜드마크 검출\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "            # print(\"얼굴 검출 중\")\n",
    "\n",
    "            # 얼굴 랜드마크를 프레임에 표시\n",
    "            if results.multi_face_landmarks:\n",
    "                frame_count_with_landmarks += 1\n",
    "\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image=frame, \n",
    "                                              landmark_list=face_landmarks, \n",
    "                                              connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                              landmark_drawing_spec=drawing_spec, \n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                              landmark_drawing_spec=drawing_spec,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                                              landmark_drawing_spec=None,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "        # 처리가 끝나면 리소스 해제\n",
    "        cap.release()\n",
    "\n",
    "    Detection = frame_count_with_landmarks / total_frames\n",
    "    N_Detection = 1 - Detection\n",
    "\n",
    "    # 결과 데이터 추가\n",
    "    data = {\n",
    "        \"Total_Frame\": total_frames,\n",
    "        \"Detection_Frame\": frame_count_with_landmarks,\n",
    "        \"Probability\": Detection,\n",
    "        \"No_Probability\": N_Detection,\n",
    "        \"Video_Name\": video_name\n",
    "    }\n",
    "\n",
    "    # 결과 데이터 저장\n",
    "    with open(f\"{video_name}.json\", 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "        print('json파일 생성')\n",
    "    try:\n",
    "        # RDS에 데이터 삽입\n",
    "        print(\"rds 전\")\n",
    "        insert_data_to_rds(f\"{video_name}.json\")\n",
    "    except Exception as e:\n",
    "        print(\"error occurred: \", str(e))\n",
    "    # 끝\n",
    "    print(\"데이터 삽입이 완료되었습니다.\")\n",
    "print(3)\n",
    "def get_latest_video_name(bucket_name):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=\"AKIAWZMQVI3Z537F5OOB\", aws_secret_access_key=\"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\")\n",
    "\n",
    "    # S3 버킷 내에서 객체 목록을 가져옴\n",
    "    response = s3.list_objects(Bucket=bucket_name)\n",
    "\n",
    "    # 가장 최근에 업로드된 객체 선택\n",
    "    latest_object = max(response['Contents'], key=lambda x: x['LastModified'])\n",
    "\n",
    "    # 파일 이름 반환 (확장자 제외)\n",
    "    latest_video_name = os.path.splitext(os.path.basename(latest_object['Key']))[0]\n",
    "\n",
    "    return latest_video_name\n",
    "print(4)\n",
    "if __name__ == '__main__':\n",
    "    # S3 버킷 이름\n",
    "    print(\"os.environ: \", os.environ)\n",
    "    s3_bucket_name = '3-example-video'\n",
    "\n",
    "    # 최근에 업로드된 동영상 이름 가져오기\n",
    "    latest_video_name = get_latest_video_name(s3_bucket_name)\n",
    "    print('latest_video_name : ', latest_video_name)\n",
    "    # 동영상 처리 함수 호출\n",
    "    process_video(latest_video_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\jhs\\appdata\\roaming\\python\\python311\\site-packages (0.10.8)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\JHS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\JHS\\AppData\\Roaming\\Python\\Python311\\site-packages\\~ediapipe'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\n",
      "mysql-connector-python 8.2.0 requires protobuf<=4.21.12,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.10.9-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\jhs\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (1.24.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\jhs\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (4.8.1.78)\n",
      "Collecting protobuf<4,>=3.11 (from mediapipe)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\jhs\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jhs\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jhs\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jhs\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Downloading mediapipe-0.10.9-cp311-cp311-win_amd64.whl (50.5 MB)\n",
      "   ---------------------------------------- 0.0/50.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/50.5 MB 660.6 kB/s eta 0:01:17\n",
      "   ---------------------------------------- 0.1/50.5 MB 656.4 kB/s eta 0:01:17\n",
      "   ---------------------------------------- 0.2/50.5 MB 1.2 MB/s eta 0:00:42\n",
      "   ---------------------------------------- 0.4/50.5 MB 2.4 MB/s eta 0:00:22\n",
      "    --------------------------------------- 0.8/50.5 MB 3.4 MB/s eta 0:00:15\n",
      "    --------------------------------------- 1.2/50.5 MB 4.5 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.3/50.5 MB 4.6 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.8/50.5 MB 5.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 2.2/50.5 MB 5.3 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.6/50.5 MB 5.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 3.1/50.5 MB 6.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 3.6/50.5 MB 6.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 4.1/50.5 MB 6.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 4.7/50.5 MB 7.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.2/50.5 MB 7.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.6/50.5 MB 7.8 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 6.2/50.5 MB 8.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.8/50.5 MB 8.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 6.9/50.5 MB 7.9 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 7.2/50.5 MB 7.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 8.1/50.5 MB 8.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 8.5/50.5 MB 8.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 9.4/50.5 MB 8.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 10.1/50.5 MB 9.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 10.4/50.5 MB 10.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 11.2/50.5 MB 10.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 11.4/50.5 MB 10.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 12.0/50.5 MB 10.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 12.7/50.5 MB 11.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 13.5/50.5 MB 11.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 14.6/50.5 MB 12.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 15.1/50.5 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 16.3/50.5 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 17.0/50.5 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 18.0/50.5 MB 15.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 19.2/50.5 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 20.4/50.5 MB 17.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 21.4/50.5 MB 18.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 22.3/50.5 MB 20.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 23.4/50.5 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 24.5/50.5 MB 21.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 25.6/50.5 MB 22.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 26.6/50.5 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 27.9/50.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 28.9/50.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 30.0/50.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 31.2/50.5 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 32.4/50.5 MB 24.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 33.6/50.5 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 34.9/50.5 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 35.9/50.5 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 37.3/50.5 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 38.2/50.5 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 39.7/50.5 MB 25.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 40.1/50.5 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 41.9/50.5 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 42.4/50.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 43.0/50.5 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 44.1/50.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 45.9/50.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 46.6/50.5 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 47.1/50.5 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 49.0/50.5 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  50.0/50.5 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  50.5/50.5 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  50.5/50.5 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 50.5/50.5 MB 19.8 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, mediapipe\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "  Attempting uninstall: mediapipe\n",
      "    Found existing installation: mediapipe 0.10.8\n",
      "    Uninstalling mediapipe-0.10.8:\n",
      "      Successfully uninstalled mediapipe-0.10.8\n",
      "Successfully installed mediapipe-0.10.9 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\jhs\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade opencv-python\n",
    "pip install --upgrade mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계\n",
      "MediaPipe version: 0.10.8\n",
      "os.environ:  environ({'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Roaming', 'CHROME_CRASHPAD_PIPE_NAME': '\\\\\\\\.\\\\pipe\\\\crashpad_16476_OLXJXISWZKMZITCC', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'DESKTOP-UJRJVA2', 'COMSPEC': 'C:\\\\Windows\\\\system32\\\\cmd.exe', 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData', 'EFC_7936': '1', 'ELECTRON_RUN_AS_NODE': '1', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\JHS', 'IGCCSVC_DB': 'AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA8S8EqCDTQUamf4y+Q/fwPgQAAAACAAAAAAAQZgAAAAEAACAAAABYLobO59sYIcFBPojXTg7anFVphXaY+r/762LUBL6RcwAAAAAOgAAAAAIAACAAAAC9UWhobV98mgIGhpX4ENNjivPu0PWKXpu211MuCHVoyWAAAAAdO9LW6CZuoD2teqXeK60LZ6bnIxjrIojON0mH/PlVyHQWrQYUB2iH8oPaQUW+hg+wX0qapEE2DXk9LD9B9CLkf4mtModXtFY8oC3TsXhH9M0csyC1gtqzIT/Z+GL5e95AAAAAThbVDRIUPcoumouyvIjq6nt9DaFtzb4dzR+8jK1buNeAlmtrdt9qCPYIai/DIT78jMX2Hbv5yV5sIAvRI182aA==', 'JPY_INTERRUPT_EVENT': '984', 'LOCALAPPDATA': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\DESKTOP-UJRJVA2', 'NUMBER_OF_PROCESSORS': '12', 'ONEDRIVE': 'C:\\\\Users\\\\전혁선\\\\OneDrive', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'OS': 'Windows_NT', 'PATH': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\cv2\\\\../../x64/vc14/bin;c:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311;c:\\\\Users\\\\JHS\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\Scripts;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 186 Stepping 3, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': 'ba03', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\Windows\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules', 'PUBLIC': 'C:\\\\Users\\\\Public', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHONIOENCODING': 'utf-8', 'PYTHONUNBUFFERED': '1', 'SESSIONNAME': 'Console', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\Windows', 'TEMP': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Temp', 'USERDOMAIN': 'DESKTOP-UJRJVA2', 'USERDOMAIN_ROAMINGPROFILE': 'DESKTOP-UJRJVA2', 'USERNAME': 'JHS', 'USERPROFILE': 'C:\\\\Users\\\\JHS', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_CODE_CACHE_PATH': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Roaming\\\\Code\\\\CachedData\\\\0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'VSCODE_CWD': 'C:\\\\Users\\\\JHS\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_IPC_HOOK': '\\\\\\\\.\\\\pipe\\\\955620448293eae12eae853ecf8a5608-1.85.1-main-sock', 'VSCODE_NLS_CONFIG': '{\"locale\":\"ko\",\"osLocale\":\"ko\",\"availableLanguages\":{\"*\":\"ko\"},\"_languagePackId\":\"8c714c23d05db6b414b8ab3c57f99fbe.ko\",\"_translationsConfigFile\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\\\\\\\\tcf.json\",\"_cacheRoot\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\",\"_resolvedLanguagePackCoreLocation\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\\\\\\\\0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2\",\"_corruptedFile\":\"C:\\\\\\\\Users\\\\\\\\JHS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Code\\\\\\\\clp\\\\\\\\8c714c23d05db6b414b8ab3c57f99fbe.ko\\\\\\\\corrupted.info\",\"_languagePackSupport\":true}', 'VSCODE_PID': '16476', 'WINDIR': 'C:\\\\Windows', 'ZES_ENABLE_SYSMAN': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'TPU_ML_PLATFORM': 'Tensorflow', 'TF2_BEHAVIOR': '1'})\n",
      "latest_video_name :  연습2\n",
      "Video downloaded from S3 to ./연습2.mp4\n",
      "download_video_from_s3 끝\n",
      "데이터 추출 전\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to parse: node {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:image\"\n  output_stream: \"SIZE:image_size\"\n}\nnode {\n  calculator: \"PreviousLoopbackCalculator\"\n  input_stream: \"MAIN:image\"\n  input_stream: \"LOOP:face_rects_from_landmarks\"\n  output_stream: \"PREV_LOOP:prev_face_rects_from_landmarks\"\n  input_stream_info {\n    tag_index: \"LOOP\"\n    back_edge: true\n  }\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"prev_face_rects_from_landmarks\"\n  output_stream: \"gated_prev_face_rects_from_landmarks\"\n  input_side_packet: \"ALLOW:use_prev_landmarks\"\n  options {\n    ext {\n      allow: true\n    }\n  }\n}\nnode {\n  calculator: \"NormalizedRectVectorHasMinSizeCalculator\"\n  input_stream: \"ITERABLE:gated_prev_face_rects_from_landmarks\"\n  output_stream: \"prev_has_enough_faces\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"image\"\n  input_stream: \"DISALLOW:prev_has_enough_faces\"\n  output_stream: \"gated_image\"\n  options {\n    ext {\n      empty_packets_as_allow: true\n    }\n  }\n}\nnode {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"SIZE:gated_image_size\"\n}\nnode {\n  name: \"facelandmarkcpu__TfLiteCustomOpResolverCalculator\"\n  calculator: \"TfLiteCustomOpResolverCalculator\"\n  output_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ToImageCalculator\"\n  calculator: \"ToImageCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.ImageToTensorCalculatorOptions\"\n    value: \"\\030\\001\\\"\\n\\r\\000\\000\\200\\277\\025\\000\\000\\200?0\\001\\010\\200\\001\\020\\200\\001\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__SsdAnchorsCalculator\"\n  calculator: \"SsdAnchorsCalculator\"\n  output_side_packet: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.SsdAnchorsCalculatorOptions\"\n    value: \"\\035\\000\\000\\030>%\\000\\000@?-\\000\\000\\000?5\\000\\000\\000?]\\000\\000\\200?p\\001\\010\\200\\001\\020\\200\\0018\\004P\\010P\\020P\\020P\\020m\\000\\000\\200?\"\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_1\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    ext {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_2\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    ext {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark_with_attention.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  input_side_packet: \"C0__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  input_side_packet: \"C1__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__LocalFileContentsCalculator\"\n  calculator: \"LocalFileContentsCalculator\"\n  input_side_packet: \"FILE_PATH:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"CONTENTS:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__TfLiteModelCalculator\"\n  calculator: \"TfLiteModelCalculator\"\n  input_side_packet: \"MODEL_BLOB:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n  output_side_packet: \"MODEL:facelandmarkcpu__model\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__inferencecalculator__facedetectionshortrangecpu__facedetectionshortrange__facedetection__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.InferenceCalculatorOptions\"\n    value: \"*\\002\\\"\\000\\nBmediapipe/modules/face_detection/face_detection_short_range.tflite\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__TensorsToDetectionsCalculator\"\n  calculator: \"TensorsToDetectionsCalculator\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  output_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  input_side_packet: \"ANCHORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.TensorsToDetectionsCalculatorOptions\"\n    value: \"\\010\\001\\020\\200\\007\\030\\020%\\000\\000\\000C-\\000\\000\\000C5\\000\\000\\000C=\\000\\000\\000CH\\004P\\006X\\002`\\000p\\001x\\001\\205\\001\\000\\000\\310B\\235\\001\\000\\000\\000?\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__NonMaxSuppressionCalculator\"\n  calculator: \"NonMaxSuppressionCalculator\"\n  input_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  output_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  options {\n    ext {\n      min_suppression_threshold: 0.3\n      overlap_type: INTERSECTION_OVER_UNION\n      algorithm: WEIGHTED\n    }\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__DetectionProjectionCalculator\"\n  calculator: \"DetectionProjectionCalculator\"\n  input_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  input_stream: \"PROJECTION_MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  output_stream: \"DETECTIONS:all_face_detections\"\n}\nnode {\n  calculator: \"ClipDetectionVectorSizeCalculator\"\n  input_stream: \"all_face_detections\"\n  output_stream: \"face_detections\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"BeginLoopDetectionCalculator\"\n  input_stream: \"ITERABLE:face_detections\"\n  input_stream: \"CLONE:gated_image_size\"\n  output_stream: \"ITEM:face_detection\"\n  output_stream: \"CLONE:detections_loop_image_size\"\n  output_stream: \"BATCH_END:detections_loop_end_timestamp\"\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:face_detection\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  options {\n    ext {\n      rotation_vector_start_keypoint_index: 0\n      rotation_vector_end_keypoint_index: 1\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"face_rect_from_detection\"\n  options {\n    ext {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_detection\"\n  input_stream: \"BATCH_END:detections_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_detections\"\n}\nnode {\n  calculator: \"AssociationNormRectCalculator\"\n  input_stream: \"face_rects_from_detections\"\n  input_stream: \"gated_prev_face_rects_from_landmarks\"\n  output_stream: \"face_rects\"\n  options {\n    ext {\n      min_similarity_threshold: 0.5\n    }\n  }\n}\nnode {\n  calculator: \"BeginLoopNormalizedRectCalculator\"\n  input_stream: \"ITERABLE:face_rects\"\n  input_stream: \"CLONE:0:image\"\n  input_stream: \"CLONE:1:image_size\"\n  output_stream: \"ITEM:face_rect\"\n  output_stream: \"CLONE:0:landmarks_loop_image\"\n  output_stream: \"CLONE:1:landmarks_loop_image_size\"\n  output_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n}\nnode {\n  name: \"facelandmarkcpu__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:landmarks_loop_image\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  options {\n    ext {\n      output_tensor_width: 192\n      output_tensor_height: 192\n      output_tensor_float_range {\n        min: 0\n        max: 1\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__inferencecalculator__facelandmarkcpu__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  output_stream: \"TENSORS:facelandmarkcpu__output_tensors\"\n  input_side_packet: \"MODEL:facelandmarkcpu__model\"\n  input_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n  options {\n    ext {\n      delegate {\n        xnnpack {\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"facelandmarkcpu__output_tensors\"\n  output_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_1\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  options {\n    ext {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_2\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  options {\n    ext {\n      ranges {\n        begin: 0\n        end: 6\n      }\n      ranges {\n        begin: 6\n        end: 7\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C0__:1:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  input_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C1__:1:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__face_flag_tensor\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__TensorsToFloatsCalculator\"\n  calculator: \"TensorsToFloatsCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  options {\n    ext {\n      activation: SIGMOID\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__ThresholdingCalculator\"\n  calculator: \"ThresholdingCalculator\"\n  input_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  output_stream: \"FLAG:facelandmarkcpu__face_presence\"\n  options {\n    ext {\n      threshold: 0.85\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__GateCalculator\"\n  calculator: \"GateCalculator\"\n  input_stream: \"facelandmarkcpu__landmark_tensors\"\n  input_stream: \"ALLOW:facelandmarkcpu__face_presence\"\n  output_stream: \"facelandmarkcpu__ensured_landmark_tensors\"\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C0__TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C1__TENSORS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarks__TensorsToLandmarksCalculator\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  options {\n    ext {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__SplitTensorVectorCalculator\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  options {\n    ext {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n      ranges {\n        begin: 2\n        end: 3\n      }\n      ranges {\n        begin: 3\n        end: 4\n      }\n      ranges {\n        begin: 4\n        end: 5\n      }\n      ranges {\n        begin: 5\n        end: 6\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_1\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  options {\n    ext {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_2\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  options {\n    ext {\n      num_landmarks: 80\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_3\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  options {\n    ext {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_4\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  options {\n    ext {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_5\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  options {\n    ext {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_6\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  options {\n    ext {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__LandmarksRefinementCalculator\"\n  calculator: \"LandmarksRefinementCalculator\"\n  input_stream: \"LANDMARKS:0:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  input_stream: \"LANDMARKS:1:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  input_stream: \"LANDMARKS:2:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  input_stream: \"LANDMARKS:3:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  input_stream: \"LANDMARKS:4:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  input_stream: \"LANDMARKS:5:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  output_stream: \"REFINED_LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  options {\n    ext {\n      refinement {\n        indexes_mapping: 0\n        indexes_mapping: 1\n        indexes_mapping: 2\n        indexes_mapping: 3\n        indexes_mapping: 4\n        indexes_mapping: 5\n        indexes_mapping: 6\n        indexes_mapping: 7\n        indexes_mapping: 8\n        indexes_mapping: 9\n        indexes_mapping: 10\n        indexes_mapping: 11\n        indexes_mapping: 12\n        indexes_mapping: 13\n        indexes_mapping: 14\n        indexes_mapping: 15\n        indexes_mapping: 16\n        indexes_mapping: 17\n        indexes_mapping: 18\n        indexes_mapping: 19\n        indexes_mapping: 20\n        indexes_mapping: 21\n        indexes_mapping: 22\n        indexes_mapping: 23\n        indexes_mapping: 24\n        indexes_mapping: 25\n        indexes_mapping: 26\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 29\n        indexes_mapping: 30\n        indexes_mapping: 31\n        indexes_mapping: 32\n        indexes_mapping: 33\n        indexes_mapping: 34\n        indexes_mapping: 35\n        indexes_mapping: 36\n        indexes_mapping: 37\n        indexes_mapping: 38\n        indexes_mapping: 39\n        indexes_mapping: 40\n        indexes_mapping: 41\n        indexes_mapping: 42\n        indexes_mapping: 43\n        indexes_mapping: 44\n        indexes_mapping: 45\n        indexes_mapping: 46\n        indexes_mapping: 47\n        indexes_mapping: 48\n        indexes_mapping: 49\n        indexes_mapping: 50\n        indexes_mapping: 51\n        indexes_mapping: 52\n        indexes_mapping: 53\n        indexes_mapping: 54\n        indexes_mapping: 55\n        indexes_mapping: 56\n        indexes_mapping: 57\n        indexes_mapping: 58\n        indexes_mapping: 59\n        indexes_mapping: 60\n        indexes_mapping: 61\n        indexes_mapping: 62\n        indexes_mapping: 63\n        indexes_mapping: 64\n        indexes_mapping: 65\n        indexes_mapping: 66\n        indexes_mapping: 67\n        indexes_mapping: 68\n        indexes_mapping: 69\n        indexes_mapping: 70\n        indexes_mapping: 71\n        indexes_mapping: 72\n        indexes_mapping: 73\n        indexes_mapping: 74\n        indexes_mapping: 75\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 78\n        indexes_mapping: 79\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 83\n        indexes_mapping: 84\n        indexes_mapping: 85\n        indexes_mapping: 86\n        indexes_mapping: 87\n        indexes_mapping: 88\n        indexes_mapping: 89\n        indexes_mapping: 90\n        indexes_mapping: 91\n        indexes_mapping: 92\n        indexes_mapping: 93\n        indexes_mapping: 94\n        indexes_mapping: 95\n        indexes_mapping: 96\n        indexes_mapping: 97\n        indexes_mapping: 98\n        indexes_mapping: 99\n        indexes_mapping: 100\n        indexes_mapping: 101\n        indexes_mapping: 102\n        indexes_mapping: 103\n        indexes_mapping: 104\n        indexes_mapping: 105\n        indexes_mapping: 106\n        indexes_mapping: 107\n        indexes_mapping: 108\n        indexes_mapping: 109\n        indexes_mapping: 110\n        indexes_mapping: 111\n        indexes_mapping: 112\n        indexes_mapping: 113\n        indexes_mapping: 114\n        indexes_mapping: 115\n        indexes_mapping: 116\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 122\n        indexes_mapping: 123\n        indexes_mapping: 124\n        indexes_mapping: 125\n        indexes_mapping: 126\n        indexes_mapping: 127\n        indexes_mapping: 128\n        indexes_mapping: 129\n        indexes_mapping: 130\n        indexes_mapping: 131\n        indexes_mapping: 132\n        indexes_mapping: 133\n        indexes_mapping: 134\n        indexes_mapping: 135\n        indexes_mapping: 136\n        indexes_mapping: 137\n        indexes_mapping: 138\n        indexes_mapping: 139\n        indexes_mapping: 140\n        indexes_mapping: 141\n        indexes_mapping: 142\n        indexes_mapping: 143\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 146\n        indexes_mapping: 147\n        indexes_mapping: 148\n        indexes_mapping: 149\n        indexes_mapping: 150\n        indexes_mapping: 151\n        indexes_mapping: 152\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 156\n        indexes_mapping: 157\n        indexes_mapping: 158\n        indexes_mapping: 159\n        indexes_mapping: 160\n        indexes_mapping: 161\n        indexes_mapping: 162\n        indexes_mapping: 163\n        indexes_mapping: 164\n        indexes_mapping: 165\n        indexes_mapping: 166\n        indexes_mapping: 167\n        indexes_mapping: 168\n        indexes_mapping: 169\n        indexes_mapping: 170\n        indexes_mapping: 171\n        indexes_mapping: 172\n        indexes_mapping: 173\n        indexes_mapping: 174\n        indexes_mapping: 175\n        indexes_mapping: 176\n        indexes_mapping: 177\n        indexes_mapping: 178\n        indexes_mapping: 179\n        indexes_mapping: 180\n        indexes_mapping: 181\n        indexes_mapping: 182\n        indexes_mapping: 183\n        indexes_mapping: 184\n        indexes_mapping: 185\n        indexes_mapping: 186\n        indexes_mapping: 187\n        indexes_mapping: 188\n        indexes_mapping: 189\n        indexes_mapping: 190\n        indexes_mapping: 191\n        indexes_mapping: 192\n        indexes_mapping: 193\n        indexes_mapping: 194\n        indexes_mapping: 195\n        indexes_mapping: 196\n        indexes_mapping: 197\n        indexes_mapping: 198\n        indexes_mapping: 199\n        indexes_mapping: 200\n        indexes_mapping: 201\n        indexes_mapping: 202\n        indexes_mapping: 203\n        indexes_mapping: 204\n        indexes_mapping: 205\n        indexes_mapping: 206\n        indexes_mapping: 207\n        indexes_mapping: 208\n        indexes_mapping: 209\n        indexes_mapping: 210\n        indexes_mapping: 211\n        indexes_mapping: 212\n        indexes_mapping: 213\n        indexes_mapping: 214\n        indexes_mapping: 215\n        indexes_mapping: 216\n        indexes_mapping: 217\n        indexes_mapping: 218\n        indexes_mapping: 219\n        indexes_mapping: 220\n        indexes_mapping: 221\n        indexes_mapping: 222\n        indexes_mapping: 223\n        indexes_mapping: 224\n        indexes_mapping: 225\n        indexes_mapping: 226\n        indexes_mapping: 227\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 234\n        indexes_mapping: 235\n        indexes_mapping: 236\n        indexes_mapping: 237\n        indexes_mapping: 238\n        indexes_mapping: 239\n        indexes_mapping: 240\n        indexes_mapping: 241\n        indexes_mapping: 242\n        indexes_mapping: 243\n        indexes_mapping: 244\n        indexes_mapping: 245\n        indexes_mapping: 246\n        indexes_mapping: 247\n        indexes_mapping: 248\n        indexes_mapping: 249\n        indexes_mapping: 250\n        indexes_mapping: 251\n        indexes_mapping: 252\n        indexes_mapping: 253\n        indexes_mapping: 254\n        indexes_mapping: 255\n        indexes_mapping: 256\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 259\n        indexes_mapping: 260\n        indexes_mapping: 261\n        indexes_mapping: 262\n        indexes_mapping: 263\n        indexes_mapping: 264\n        indexes_mapping: 265\n        indexes_mapping: 266\n        indexes_mapping: 267\n        indexes_mapping: 268\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 273\n        indexes_mapping: 274\n        indexes_mapping: 275\n        indexes_mapping: 276\n        indexes_mapping: 277\n        indexes_mapping: 278\n        indexes_mapping: 279\n        indexes_mapping: 280\n        indexes_mapping: 281\n        indexes_mapping: 282\n        indexes_mapping: 283\n        indexes_mapping: 284\n        indexes_mapping: 285\n        indexes_mapping: 286\n        indexes_mapping: 287\n        indexes_mapping: 288\n        indexes_mapping: 289\n        indexes_mapping: 290\n        indexes_mapping: 291\n        indexes_mapping: 292\n        indexes_mapping: 293\n        indexes_mapping: 294\n        indexes_mapping: 295\n        indexes_mapping: 296\n        indexes_mapping: 297\n        indexes_mapping: 298\n        indexes_mapping: 299\n        indexes_mapping: 300\n        indexes_mapping: 301\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 305\n        indexes_mapping: 306\n        indexes_mapping: 307\n        indexes_mapping: 308\n        indexes_mapping: 309\n        indexes_mapping: 310\n        indexes_mapping: 311\n        indexes_mapping: 312\n        indexes_mapping: 313\n        indexes_mapping: 314\n        indexes_mapping: 315\n        indexes_mapping: 316\n        indexes_mapping: 317\n        indexes_mapping: 318\n        indexes_mapping: 319\n        indexes_mapping: 320\n        indexes_mapping: 321\n        indexes_mapping: 322\n        indexes_mapping: 323\n        indexes_mapping: 324\n        indexes_mapping: 325\n        indexes_mapping: 326\n        indexes_mapping: 327\n        indexes_mapping: 328\n        indexes_mapping: 329\n        indexes_mapping: 330\n        indexes_mapping: 331\n        indexes_mapping: 332\n        indexes_mapping: 333\n        indexes_mapping: 334\n        indexes_mapping: 335\n        indexes_mapping: 336\n        indexes_mapping: 337\n        indexes_mapping: 338\n        indexes_mapping: 339\n        indexes_mapping: 340\n        indexes_mapping: 341\n        indexes_mapping: 342\n        indexes_mapping: 343\n        indexes_mapping: 344\n        indexes_mapping: 345\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 351\n        indexes_mapping: 352\n        indexes_mapping: 353\n        indexes_mapping: 354\n        indexes_mapping: 355\n        indexes_mapping: 356\n        indexes_mapping: 357\n        indexes_mapping: 358\n        indexes_mapping: 359\n        indexes_mapping: 360\n        indexes_mapping: 361\n        indexes_mapping: 362\n        indexes_mapping: 363\n        indexes_mapping: 364\n        indexes_mapping: 365\n        indexes_mapping: 366\n        indexes_mapping: 367\n        indexes_mapping: 368\n        indexes_mapping: 369\n        indexes_mapping: 370\n        indexes_mapping: 371\n        indexes_mapping: 372\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 375\n        indexes_mapping: 376\n        indexes_mapping: 377\n        indexes_mapping: 378\n        indexes_mapping: 379\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 383\n        indexes_mapping: 384\n        indexes_mapping: 385\n        indexes_mapping: 386\n        indexes_mapping: 387\n        indexes_mapping: 388\n        indexes_mapping: 389\n        indexes_mapping: 390\n        indexes_mapping: 391\n        indexes_mapping: 392\n        indexes_mapping: 393\n        indexes_mapping: 394\n        indexes_mapping: 395\n        indexes_mapping: 396\n        indexes_mapping: 397\n        indexes_mapping: 398\n        indexes_mapping: 399\n        indexes_mapping: 400\n        indexes_mapping: 401\n        indexes_mapping: 402\n        indexes_mapping: 403\n        indexes_mapping: 404\n        indexes_mapping: 405\n        indexes_mapping: 406\n        indexes_mapping: 407\n        indexes_mapping: 408\n        indexes_mapping: 409\n        indexes_mapping: 410\n        indexes_mapping: 411\n        indexes_mapping: 412\n        indexes_mapping: 413\n        indexes_mapping: 414\n        indexes_mapping: 415\n        indexes_mapping: 416\n        indexes_mapping: 417\n        indexes_mapping: 418\n        indexes_mapping: 419\n        indexes_mapping: 420\n        indexes_mapping: 421\n        indexes_mapping: 422\n        indexes_mapping: 423\n        indexes_mapping: 424\n        indexes_mapping: 425\n        indexes_mapping: 426\n        indexes_mapping: 427\n        indexes_mapping: 428\n        indexes_mapping: 429\n        indexes_mapping: 430\n        indexes_mapping: 431\n        indexes_mapping: 432\n        indexes_mapping: 433\n        indexes_mapping: 434\n        indexes_mapping: 435\n        indexes_mapping: 436\n        indexes_mapping: 437\n        indexes_mapping: 438\n        indexes_mapping: 439\n        indexes_mapping: 440\n        indexes_mapping: 441\n        indexes_mapping: 442\n        indexes_mapping: 443\n        indexes_mapping: 444\n        indexes_mapping: 445\n        indexes_mapping: 446\n        indexes_mapping: 447\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 454\n        indexes_mapping: 455\n        indexes_mapping: 456\n        indexes_mapping: 457\n        indexes_mapping: 458\n        indexes_mapping: 459\n        indexes_mapping: 460\n        indexes_mapping: 461\n        indexes_mapping: 462\n        indexes_mapping: 463\n        indexes_mapping: 464\n        indexes_mapping: 465\n        indexes_mapping: 466\n        indexes_mapping: 467\n        z_refinement {\n          copy {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 61\n        indexes_mapping: 146\n        indexes_mapping: 91\n        indexes_mapping: 181\n        indexes_mapping: 84\n        indexes_mapping: 17\n        indexes_mapping: 314\n        indexes_mapping: 405\n        indexes_mapping: 321\n        indexes_mapping: 375\n        indexes_mapping: 291\n        indexes_mapping: 185\n        indexes_mapping: 40\n        indexes_mapping: 39\n        indexes_mapping: 37\n        indexes_mapping: 0\n        indexes_mapping: 267\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 409\n        indexes_mapping: 78\n        indexes_mapping: 95\n        indexes_mapping: 88\n        indexes_mapping: 178\n        indexes_mapping: 87\n        indexes_mapping: 14\n        indexes_mapping: 317\n        indexes_mapping: 402\n        indexes_mapping: 318\n        indexes_mapping: 324\n        indexes_mapping: 308\n        indexes_mapping: 191\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 13\n        indexes_mapping: 312\n        indexes_mapping: 311\n        indexes_mapping: 310\n        indexes_mapping: 415\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 90\n        indexes_mapping: 180\n        indexes_mapping: 85\n        indexes_mapping: 16\n        indexes_mapping: 315\n        indexes_mapping: 404\n        indexes_mapping: 320\n        indexes_mapping: 307\n        indexes_mapping: 306\n        indexes_mapping: 184\n        indexes_mapping: 74\n        indexes_mapping: 73\n        indexes_mapping: 72\n        indexes_mapping: 11\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 408\n        indexes_mapping: 62\n        indexes_mapping: 96\n        indexes_mapping: 89\n        indexes_mapping: 179\n        indexes_mapping: 86\n        indexes_mapping: 15\n        indexes_mapping: 316\n        indexes_mapping: 403\n        indexes_mapping: 319\n        indexes_mapping: 325\n        indexes_mapping: 292\n        indexes_mapping: 183\n        indexes_mapping: 42\n        indexes_mapping: 41\n        indexes_mapping: 38\n        indexes_mapping: 12\n        indexes_mapping: 268\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 407\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 33\n        indexes_mapping: 7\n        indexes_mapping: 163\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 133\n        indexes_mapping: 246\n        indexes_mapping: 161\n        indexes_mapping: 160\n        indexes_mapping: 159\n        indexes_mapping: 158\n        indexes_mapping: 157\n        indexes_mapping: 173\n        indexes_mapping: 130\n        indexes_mapping: 25\n        indexes_mapping: 110\n        indexes_mapping: 24\n        indexes_mapping: 23\n        indexes_mapping: 22\n        indexes_mapping: 26\n        indexes_mapping: 112\n        indexes_mapping: 243\n        indexes_mapping: 247\n        indexes_mapping: 30\n        indexes_mapping: 29\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 56\n        indexes_mapping: 190\n        indexes_mapping: 226\n        indexes_mapping: 31\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 244\n        indexes_mapping: 113\n        indexes_mapping: 225\n        indexes_mapping: 224\n        indexes_mapping: 223\n        indexes_mapping: 222\n        indexes_mapping: 221\n        indexes_mapping: 189\n        indexes_mapping: 35\n        indexes_mapping: 124\n        indexes_mapping: 46\n        indexes_mapping: 53\n        indexes_mapping: 52\n        indexes_mapping: 65\n        indexes_mapping: 143\n        indexes_mapping: 111\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 128\n        indexes_mapping: 245\n        indexes_mapping: 156\n        indexes_mapping: 70\n        indexes_mapping: 63\n        indexes_mapping: 105\n        indexes_mapping: 66\n        indexes_mapping: 107\n        indexes_mapping: 55\n        indexes_mapping: 193\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 263\n        indexes_mapping: 249\n        indexes_mapping: 390\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 362\n        indexes_mapping: 466\n        indexes_mapping: 388\n        indexes_mapping: 387\n        indexes_mapping: 386\n        indexes_mapping: 385\n        indexes_mapping: 384\n        indexes_mapping: 398\n        indexes_mapping: 359\n        indexes_mapping: 255\n        indexes_mapping: 339\n        indexes_mapping: 254\n        indexes_mapping: 253\n        indexes_mapping: 252\n        indexes_mapping: 256\n        indexes_mapping: 341\n        indexes_mapping: 463\n        indexes_mapping: 467\n        indexes_mapping: 260\n        indexes_mapping: 259\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 286\n        indexes_mapping: 414\n        indexes_mapping: 446\n        indexes_mapping: 261\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 464\n        indexes_mapping: 342\n        indexes_mapping: 445\n        indexes_mapping: 444\n        indexes_mapping: 443\n        indexes_mapping: 442\n        indexes_mapping: 441\n        indexes_mapping: 413\n        indexes_mapping: 265\n        indexes_mapping: 353\n        indexes_mapping: 276\n        indexes_mapping: 283\n        indexes_mapping: 282\n        indexes_mapping: 295\n        indexes_mapping: 372\n        indexes_mapping: 340\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 357\n        indexes_mapping: 465\n        indexes_mapping: 383\n        indexes_mapping: 300\n        indexes_mapping: 293\n        indexes_mapping: 334\n        indexes_mapping: 296\n        indexes_mapping: 336\n        indexes_mapping: 285\n        indexes_mapping: 417\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 468\n        indexes_mapping: 469\n        indexes_mapping: 470\n        indexes_mapping: 471\n        indexes_mapping: 472\n        z_refinement {\n          assign_average {\n            indexes_for_average: 33\n            indexes_for_average: 7\n            indexes_for_average: 163\n            indexes_for_average: 144\n            indexes_for_average: 145\n            indexes_for_average: 153\n            indexes_for_average: 154\n            indexes_for_average: 155\n            indexes_for_average: 133\n            indexes_for_average: 246\n            indexes_for_average: 161\n            indexes_for_average: 160\n            indexes_for_average: 159\n            indexes_for_average: 158\n            indexes_for_average: 157\n            indexes_for_average: 173\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 473\n        indexes_mapping: 474\n        indexes_mapping: 475\n        indexes_mapping: 476\n        indexes_mapping: 477\n        z_refinement {\n          assign_average {\n            indexes_for_average: 263\n            indexes_for_average: 249\n            indexes_for_average: 390\n            indexes_for_average: 373\n            indexes_for_average: 374\n            indexes_for_average: 380\n            indexes_for_average: 381\n            indexes_for_average: 382\n            indexes_for_average: 362\n            indexes_for_average: 466\n            indexes_for_average: 388\n            indexes_for_average: 387\n            indexes_for_average: 386\n            indexes_for_average: 385\n            indexes_for_average: 384\n            indexes_for_average: 398\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  input_stream: \"C1__LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  output_stream: \"LANDMARKS:facelandmarkcpu__landmarks\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__LandmarkProjectionCalculator\"\n  calculator: \"LandmarkProjectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:facelandmarkcpu__landmarks\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"NORM_LANDMARKS:face_landmarks\"\n}\nnode {\n  calculator: \"EndLoopNormalizedLandmarkListVectorCalculator\"\n  input_stream: \"ITEM:face_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:multi_face_landmarks\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__LandmarksToDetectionCalculator\"\n  calculator: \"LandmarksToDetectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:face_landmarks\"\n  output_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  options {\n    ext {\n      rotation_vector_start_keypoint_index: 33\n      rotation_vector_end_keypoint_index: 263\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"face_rect_from_landmarks\"\n  options {\n    ext {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_landmarks\"\n}\ninput_stream: \"IMAGE:image\"\noutput_stream: \"LANDMARKS:multi_face_landmarks\"\noutput_stream: \"DETECTIONS:face_detections\"\noutput_stream: \"ROIS_FROM_LANDMARKS:face_rects_from_landmarks\"\noutput_stream: \"ROIS_FROM_DETECTIONS:face_rects_from_detections\"\ninput_side_packet: \"NUM_FACES:num_faces\"\ninput_side_packet: \"USE_PREV_LANDMARKS:use_prev_landmarks\"\ninput_side_packet: \"WITH_ATTENTION:with_attention\"\nexecutor {\n}\ntype: \"FaceLandmarkFrontCpu\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 117\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest_video_name : \u001b[39m\u001b[38;5;124m'\u001b[39m, latest_video_name)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# 동영상 처리 함수 호출\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatest_video_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(video_name)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m데이터 추출 전\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m# 여기까지 무조건 됨\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# mediapipe FaceMesh 인스턴스 생성\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmp_face_mesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFaceMesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_image_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmax_num_faces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mrefine_landmarks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.85\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m face_mesh:\n\u001b[0;32m     43\u001b[0m     frame_count_with_landmarks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m된건가\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solutions\\face_mesh.py:95\u001b[0m, in \u001b[0;36mFaceMesh.__init__\u001b[1;34m(self, static_image_mode, max_num_faces, refine_landmarks, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     71\u001b[0m              static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m              max_num_faces\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     73\u001b[0m              refine_landmarks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     74\u001b[0m              min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     75\u001b[0m              min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a MediaPipe Face Mesh object.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m      https://solutions.mediapipe.dev/face_mesh#min_tracking_confidence.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbinary_graph_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_BINARYPB_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m      \u001b[49m\u001b[43mside_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_faces\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_faces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwith_attention\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_landmarks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_prev_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstatic_image_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcalculator_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacedetectionshortrangecpu__facedetectionshortrange__facedetection__TensorsToDetectionsCalculator.min_score_thresh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacelandmarkcpu__ThresholdingCalculator.threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_face_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solution_base.py:285\u001b[0m, in \u001b[0;36mSolutionBase.__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_options:\n\u001b[0;32m    282\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_extension(canonical_graph_config_proto\u001b[38;5;241m.\u001b[39mgraph_options,\n\u001b[0;32m    283\u001b[0m                       graph_options)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[43mcalculator_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCalculatorGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanonical_graph_config_proto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_outputs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to parse: node {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:image\"\n  output_stream: \"SIZE:image_size\"\n}\nnode {\n  calculator: \"PreviousLoopbackCalculator\"\n  input_stream: \"MAIN:image\"\n  input_stream: \"LOOP:face_rects_from_landmarks\"\n  output_stream: \"PREV_LOOP:prev_face_rects_from_landmarks\"\n  input_stream_info {\n    tag_index: \"LOOP\"\n    back_edge: true\n  }\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"prev_face_rects_from_landmarks\"\n  output_stream: \"gated_prev_face_rects_from_landmarks\"\n  input_side_packet: \"ALLOW:use_prev_landmarks\"\n  options {\n    ext {\n      allow: true\n    }\n  }\n}\nnode {\n  calculator: \"NormalizedRectVectorHasMinSizeCalculator\"\n  input_stream: \"ITERABLE:gated_prev_face_rects_from_landmarks\"\n  output_stream: \"prev_has_enough_faces\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"image\"\n  input_stream: \"DISALLOW:prev_has_enough_faces\"\n  output_stream: \"gated_image\"\n  options {\n    ext {\n      empty_packets_as_allow: true\n    }\n  }\n}\nnode {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"SIZE:gated_image_size\"\n}\nnode {\n  name: \"facelandmarkcpu__TfLiteCustomOpResolverCalculator\"\n  calculator: \"TfLiteCustomOpResolverCalculator\"\n  output_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ToImageCalculator\"\n  calculator: \"ToImageCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.ImageToTensorCalculatorOptions\"\n    value: \"\\030\\001\\\"\\n\\r\\000\\000\\200\\277\\025\\000\\000\\200?0\\001\\010\\200\\001\\020\\200\\001\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__SsdAnchorsCalculator\"\n  calculator: \"SsdAnchorsCalculator\"\n  output_side_packet: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.SsdAnchorsCalculatorOptions\"\n    value: \"\\035\\000\\000\\030>%\\000\\000@?-\\000\\000\\000?5\\000\\000\\000?]\\000\\000\\200?p\\001\\010\\200\\001\\020\\200\\0018\\004P\\010P\\020P\\020P\\020m\\000\\000\\200?\"\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_1\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    ext {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_2\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    ext {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark_with_attention.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  input_side_packet: \"C0__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  input_side_packet: \"C1__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__LocalFileContentsCalculator\"\n  calculator: \"LocalFileContentsCalculator\"\n  input_side_packet: \"FILE_PATH:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"CONTENTS:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__TfLiteModelCalculator\"\n  calculator: \"TfLiteModelCalculator\"\n  input_side_packet: \"MODEL_BLOB:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n  output_side_packet: \"MODEL:facelandmarkcpu__model\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__inferencecalculator__facedetectionshortrangecpu__facedetectionshortrange__facedetection__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.InferenceCalculatorOptions\"\n    value: \"*\\002\\\"\\000\\nBmediapipe/modules/face_detection/face_detection_short_range.tflite\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__TensorsToDetectionsCalculator\"\n  calculator: \"TensorsToDetectionsCalculator\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  output_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  input_side_packet: \"ANCHORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.TensorsToDetectionsCalculatorOptions\"\n    value: \"\\010\\001\\020\\200\\007\\030\\020%\\000\\000\\000C-\\000\\000\\000C5\\000\\000\\000C=\\000\\000\\000CH\\004P\\006X\\002`\\000p\\001x\\001\\205\\001\\000\\000\\310B\\235\\001\\000\\000\\000?\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__NonMaxSuppressionCalculator\"\n  calculator: \"NonMaxSuppressionCalculator\"\n  input_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  output_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  options {\n    ext {\n      min_suppression_threshold: 0.3\n      overlap_type: INTERSECTION_OVER_UNION\n      algorithm: WEIGHTED\n    }\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__DetectionProjectionCalculator\"\n  calculator: \"DetectionProjectionCalculator\"\n  input_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  input_stream: \"PROJECTION_MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  output_stream: \"DETECTIONS:all_face_detections\"\n}\nnode {\n  calculator: \"ClipDetectionVectorSizeCalculator\"\n  input_stream: \"all_face_detections\"\n  output_stream: \"face_detections\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"BeginLoopDetectionCalculator\"\n  input_stream: \"ITERABLE:face_detections\"\n  input_stream: \"CLONE:gated_image_size\"\n  output_stream: \"ITEM:face_detection\"\n  output_stream: \"CLONE:detections_loop_image_size\"\n  output_stream: \"BATCH_END:detections_loop_end_timestamp\"\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:face_detection\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  options {\n    ext {\n      rotation_vector_start_keypoint_index: 0\n      rotation_vector_end_keypoint_index: 1\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"face_rect_from_detection\"\n  options {\n    ext {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_detection\"\n  input_stream: \"BATCH_END:detections_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_detections\"\n}\nnode {\n  calculator: \"AssociationNormRectCalculator\"\n  input_stream: \"face_rects_from_detections\"\n  input_stream: \"gated_prev_face_rects_from_landmarks\"\n  output_stream: \"face_rects\"\n  options {\n    ext {\n      min_similarity_threshold: 0.5\n    }\n  }\n}\nnode {\n  calculator: \"BeginLoopNormalizedRectCalculator\"\n  input_stream: \"ITERABLE:face_rects\"\n  input_stream: \"CLONE:0:image\"\n  input_stream: \"CLONE:1:image_size\"\n  output_stream: \"ITEM:face_rect\"\n  output_stream: \"CLONE:0:landmarks_loop_image\"\n  output_stream: \"CLONE:1:landmarks_loop_image_size\"\n  output_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n}\nnode {\n  name: \"facelandmarkcpu__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:landmarks_loop_image\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  options {\n    ext {\n      output_tensor_width: 192\n      output_tensor_height: 192\n      output_tensor_float_range {\n        min: 0\n        max: 1\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__inferencecalculator__facelandmarkcpu__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  output_stream: \"TENSORS:facelandmarkcpu__output_tensors\"\n  input_side_packet: \"MODEL:facelandmarkcpu__model\"\n  input_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n  options {\n    ext {\n      delegate {\n        xnnpack {\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"facelandmarkcpu__output_tensors\"\n  output_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_1\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  options {\n    ext {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_2\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  options {\n    ext {\n      ranges {\n        begin: 0\n        end: 6\n      }\n      ranges {\n        begin: 6\n        end: 7\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C0__:1:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  input_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C1__:1:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__face_flag_tensor\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__TensorsToFloatsCalculator\"\n  calculator: \"TensorsToFloatsCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  options {\n    ext {\n      activation: SIGMOID\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__ThresholdingCalculator\"\n  calculator: \"ThresholdingCalculator\"\n  input_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  output_stream: \"FLAG:facelandmarkcpu__face_presence\"\n  options {\n    ext {\n      threshold: 0.85\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__GateCalculator\"\n  calculator: \"GateCalculator\"\n  input_stream: \"facelandmarkcpu__landmark_tensors\"\n  input_stream: \"ALLOW:facelandmarkcpu__face_presence\"\n  output_stream: \"facelandmarkcpu__ensured_landmark_tensors\"\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C0__TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C1__TENSORS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarks__TensorsToLandmarksCalculator\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  options {\n    ext {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__SplitTensorVectorCalculator\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  options {\n    ext {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n      ranges {\n        begin: 2\n        end: 3\n      }\n      ranges {\n        begin: 3\n        end: 4\n      }\n      ranges {\n        begin: 4\n        end: 5\n      }\n      ranges {\n        begin: 5\n        end: 6\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_1\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  options {\n    ext {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_2\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  options {\n    ext {\n      num_landmarks: 80\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_3\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  options {\n    ext {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_4\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  options {\n    ext {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_5\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  options {\n    ext {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_6\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  options {\n    ext {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__LandmarksRefinementCalculator\"\n  calculator: \"LandmarksRefinementCalculator\"\n  input_stream: \"LANDMARKS:0:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  input_stream: \"LANDMARKS:1:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  input_stream: \"LANDMARKS:2:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  input_stream: \"LANDMARKS:3:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  input_stream: \"LANDMARKS:4:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  input_stream: \"LANDMARKS:5:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  output_stream: \"REFINED_LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  options {\n    ext {\n      refinement {\n        indexes_mapping: 0\n        indexes_mapping: 1\n        indexes_mapping: 2\n        indexes_mapping: 3\n        indexes_mapping: 4\n        indexes_mapping: 5\n        indexes_mapping: 6\n        indexes_mapping: 7\n        indexes_mapping: 8\n        indexes_mapping: 9\n        indexes_mapping: 10\n        indexes_mapping: 11\n        indexes_mapping: 12\n        indexes_mapping: 13\n        indexes_mapping: 14\n        indexes_mapping: 15\n        indexes_mapping: 16\n        indexes_mapping: 17\n        indexes_mapping: 18\n        indexes_mapping: 19\n        indexes_mapping: 20\n        indexes_mapping: 21\n        indexes_mapping: 22\n        indexes_mapping: 23\n        indexes_mapping: 24\n        indexes_mapping: 25\n        indexes_mapping: 26\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 29\n        indexes_mapping: 30\n        indexes_mapping: 31\n        indexes_mapping: 32\n        indexes_mapping: 33\n        indexes_mapping: 34\n        indexes_mapping: 35\n        indexes_mapping: 36\n        indexes_mapping: 37\n        indexes_mapping: 38\n        indexes_mapping: 39\n        indexes_mapping: 40\n        indexes_mapping: 41\n        indexes_mapping: 42\n        indexes_mapping: 43\n        indexes_mapping: 44\n        indexes_mapping: 45\n        indexes_mapping: 46\n        indexes_mapping: 47\n        indexes_mapping: 48\n        indexes_mapping: 49\n        indexes_mapping: 50\n        indexes_mapping: 51\n        indexes_mapping: 52\n        indexes_mapping: 53\n        indexes_mapping: 54\n        indexes_mapping: 55\n        indexes_mapping: 56\n        indexes_mapping: 57\n        indexes_mapping: 58\n        indexes_mapping: 59\n        indexes_mapping: 60\n        indexes_mapping: 61\n        indexes_mapping: 62\n        indexes_mapping: 63\n        indexes_mapping: 64\n        indexes_mapping: 65\n        indexes_mapping: 66\n        indexes_mapping: 67\n        indexes_mapping: 68\n        indexes_mapping: 69\n        indexes_mapping: 70\n        indexes_mapping: 71\n        indexes_mapping: 72\n        indexes_mapping: 73\n        indexes_mapping: 74\n        indexes_mapping: 75\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 78\n        indexes_mapping: 79\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 83\n        indexes_mapping: 84\n        indexes_mapping: 85\n        indexes_mapping: 86\n        indexes_mapping: 87\n        indexes_mapping: 88\n        indexes_mapping: 89\n        indexes_mapping: 90\n        indexes_mapping: 91\n        indexes_mapping: 92\n        indexes_mapping: 93\n        indexes_mapping: 94\n        indexes_mapping: 95\n        indexes_mapping: 96\n        indexes_mapping: 97\n        indexes_mapping: 98\n        indexes_mapping: 99\n        indexes_mapping: 100\n        indexes_mapping: 101\n        indexes_mapping: 102\n        indexes_mapping: 103\n        indexes_mapping: 104\n        indexes_mapping: 105\n        indexes_mapping: 106\n        indexes_mapping: 107\n        indexes_mapping: 108\n        indexes_mapping: 109\n        indexes_mapping: 110\n        indexes_mapping: 111\n        indexes_mapping: 112\n        indexes_mapping: 113\n        indexes_mapping: 114\n        indexes_mapping: 115\n        indexes_mapping: 116\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 122\n        indexes_mapping: 123\n        indexes_mapping: 124\n        indexes_mapping: 125\n        indexes_mapping: 126\n        indexes_mapping: 127\n        indexes_mapping: 128\n        indexes_mapping: 129\n        indexes_mapping: 130\n        indexes_mapping: 131\n        indexes_mapping: 132\n        indexes_mapping: 133\n        indexes_mapping: 134\n        indexes_mapping: 135\n        indexes_mapping: 136\n        indexes_mapping: 137\n        indexes_mapping: 138\n        indexes_mapping: 139\n        indexes_mapping: 140\n        indexes_mapping: 141\n        indexes_mapping: 142\n        indexes_mapping: 143\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 146\n        indexes_mapping: 147\n        indexes_mapping: 148\n        indexes_mapping: 149\n        indexes_mapping: 150\n        indexes_mapping: 151\n        indexes_mapping: 152\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 156\n        indexes_mapping: 157\n        indexes_mapping: 158\n        indexes_mapping: 159\n        indexes_mapping: 160\n        indexes_mapping: 161\n        indexes_mapping: 162\n        indexes_mapping: 163\n        indexes_mapping: 164\n        indexes_mapping: 165\n        indexes_mapping: 166\n        indexes_mapping: 167\n        indexes_mapping: 168\n        indexes_mapping: 169\n        indexes_mapping: 170\n        indexes_mapping: 171\n        indexes_mapping: 172\n        indexes_mapping: 173\n        indexes_mapping: 174\n        indexes_mapping: 175\n        indexes_mapping: 176\n        indexes_mapping: 177\n        indexes_mapping: 178\n        indexes_mapping: 179\n        indexes_mapping: 180\n        indexes_mapping: 181\n        indexes_mapping: 182\n        indexes_mapping: 183\n        indexes_mapping: 184\n        indexes_mapping: 185\n        indexes_mapping: 186\n        indexes_mapping: 187\n        indexes_mapping: 188\n        indexes_mapping: 189\n        indexes_mapping: 190\n        indexes_mapping: 191\n        indexes_mapping: 192\n        indexes_mapping: 193\n        indexes_mapping: 194\n        indexes_mapping: 195\n        indexes_mapping: 196\n        indexes_mapping: 197\n        indexes_mapping: 198\n        indexes_mapping: 199\n        indexes_mapping: 200\n        indexes_mapping: 201\n        indexes_mapping: 202\n        indexes_mapping: 203\n        indexes_mapping: 204\n        indexes_mapping: 205\n        indexes_mapping: 206\n        indexes_mapping: 207\n        indexes_mapping: 208\n        indexes_mapping: 209\n        indexes_mapping: 210\n        indexes_mapping: 211\n        indexes_mapping: 212\n        indexes_mapping: 213\n        indexes_mapping: 214\n        indexes_mapping: 215\n        indexes_mapping: 216\n        indexes_mapping: 217\n        indexes_mapping: 218\n        indexes_mapping: 219\n        indexes_mapping: 220\n        indexes_mapping: 221\n        indexes_mapping: 222\n        indexes_mapping: 223\n        indexes_mapping: 224\n        indexes_mapping: 225\n        indexes_mapping: 226\n        indexes_mapping: 227\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 234\n        indexes_mapping: 235\n        indexes_mapping: 236\n        indexes_mapping: 237\n        indexes_mapping: 238\n        indexes_mapping: 239\n        indexes_mapping: 240\n        indexes_mapping: 241\n        indexes_mapping: 242\n        indexes_mapping: 243\n        indexes_mapping: 244\n        indexes_mapping: 245\n        indexes_mapping: 246\n        indexes_mapping: 247\n        indexes_mapping: 248\n        indexes_mapping: 249\n        indexes_mapping: 250\n        indexes_mapping: 251\n        indexes_mapping: 252\n        indexes_mapping: 253\n        indexes_mapping: 254\n        indexes_mapping: 255\n        indexes_mapping: 256\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 259\n        indexes_mapping: 260\n        indexes_mapping: 261\n        indexes_mapping: 262\n        indexes_mapping: 263\n        indexes_mapping: 264\n        indexes_mapping: 265\n        indexes_mapping: 266\n        indexes_mapping: 267\n        indexes_mapping: 268\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 273\n        indexes_mapping: 274\n        indexes_mapping: 275\n        indexes_mapping: 276\n        indexes_mapping: 277\n        indexes_mapping: 278\n        indexes_mapping: 279\n        indexes_mapping: 280\n        indexes_mapping: 281\n        indexes_mapping: 282\n        indexes_mapping: 283\n        indexes_mapping: 284\n        indexes_mapping: 285\n        indexes_mapping: 286\n        indexes_mapping: 287\n        indexes_mapping: 288\n        indexes_mapping: 289\n        indexes_mapping: 290\n        indexes_mapping: 291\n        indexes_mapping: 292\n        indexes_mapping: 293\n        indexes_mapping: 294\n        indexes_mapping: 295\n        indexes_mapping: 296\n        indexes_mapping: 297\n        indexes_mapping: 298\n        indexes_mapping: 299\n        indexes_mapping: 300\n        indexes_mapping: 301\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 305\n        indexes_mapping: 306\n        indexes_mapping: 307\n        indexes_mapping: 308\n        indexes_mapping: 309\n        indexes_mapping: 310\n        indexes_mapping: 311\n        indexes_mapping: 312\n        indexes_mapping: 313\n        indexes_mapping: 314\n        indexes_mapping: 315\n        indexes_mapping: 316\n        indexes_mapping: 317\n        indexes_mapping: 318\n        indexes_mapping: 319\n        indexes_mapping: 320\n        indexes_mapping: 321\n        indexes_mapping: 322\n        indexes_mapping: 323\n        indexes_mapping: 324\n        indexes_mapping: 325\n        indexes_mapping: 326\n        indexes_mapping: 327\n        indexes_mapping: 328\n        indexes_mapping: 329\n        indexes_mapping: 330\n        indexes_mapping: 331\n        indexes_mapping: 332\n        indexes_mapping: 333\n        indexes_mapping: 334\n        indexes_mapping: 335\n        indexes_mapping: 336\n        indexes_mapping: 337\n        indexes_mapping: 338\n        indexes_mapping: 339\n        indexes_mapping: 340\n        indexes_mapping: 341\n        indexes_mapping: 342\n        indexes_mapping: 343\n        indexes_mapping: 344\n        indexes_mapping: 345\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 351\n        indexes_mapping: 352\n        indexes_mapping: 353\n        indexes_mapping: 354\n        indexes_mapping: 355\n        indexes_mapping: 356\n        indexes_mapping: 357\n        indexes_mapping: 358\n        indexes_mapping: 359\n        indexes_mapping: 360\n        indexes_mapping: 361\n        indexes_mapping: 362\n        indexes_mapping: 363\n        indexes_mapping: 364\n        indexes_mapping: 365\n        indexes_mapping: 366\n        indexes_mapping: 367\n        indexes_mapping: 368\n        indexes_mapping: 369\n        indexes_mapping: 370\n        indexes_mapping: 371\n        indexes_mapping: 372\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 375\n        indexes_mapping: 376\n        indexes_mapping: 377\n        indexes_mapping: 378\n        indexes_mapping: 379\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 383\n        indexes_mapping: 384\n        indexes_mapping: 385\n        indexes_mapping: 386\n        indexes_mapping: 387\n        indexes_mapping: 388\n        indexes_mapping: 389\n        indexes_mapping: 390\n        indexes_mapping: 391\n        indexes_mapping: 392\n        indexes_mapping: 393\n        indexes_mapping: 394\n        indexes_mapping: 395\n        indexes_mapping: 396\n        indexes_mapping: 397\n        indexes_mapping: 398\n        indexes_mapping: 399\n        indexes_mapping: 400\n        indexes_mapping: 401\n        indexes_mapping: 402\n        indexes_mapping: 403\n        indexes_mapping: 404\n        indexes_mapping: 405\n        indexes_mapping: 406\n        indexes_mapping: 407\n        indexes_mapping: 408\n        indexes_mapping: 409\n        indexes_mapping: 410\n        indexes_mapping: 411\n        indexes_mapping: 412\n        indexes_mapping: 413\n        indexes_mapping: 414\n        indexes_mapping: 415\n        indexes_mapping: 416\n        indexes_mapping: 417\n        indexes_mapping: 418\n        indexes_mapping: 419\n        indexes_mapping: 420\n        indexes_mapping: 421\n        indexes_mapping: 422\n        indexes_mapping: 423\n        indexes_mapping: 424\n        indexes_mapping: 425\n        indexes_mapping: 426\n        indexes_mapping: 427\n        indexes_mapping: 428\n        indexes_mapping: 429\n        indexes_mapping: 430\n        indexes_mapping: 431\n        indexes_mapping: 432\n        indexes_mapping: 433\n        indexes_mapping: 434\n        indexes_mapping: 435\n        indexes_mapping: 436\n        indexes_mapping: 437\n        indexes_mapping: 438\n        indexes_mapping: 439\n        indexes_mapping: 440\n        indexes_mapping: 441\n        indexes_mapping: 442\n        indexes_mapping: 443\n        indexes_mapping: 444\n        indexes_mapping: 445\n        indexes_mapping: 446\n        indexes_mapping: 447\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 454\n        indexes_mapping: 455\n        indexes_mapping: 456\n        indexes_mapping: 457\n        indexes_mapping: 458\n        indexes_mapping: 459\n        indexes_mapping: 460\n        indexes_mapping: 461\n        indexes_mapping: 462\n        indexes_mapping: 463\n        indexes_mapping: 464\n        indexes_mapping: 465\n        indexes_mapping: 466\n        indexes_mapping: 467\n        z_refinement {\n          copy {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 61\n        indexes_mapping: 146\n        indexes_mapping: 91\n        indexes_mapping: 181\n        indexes_mapping: 84\n        indexes_mapping: 17\n        indexes_mapping: 314\n        indexes_mapping: 405\n        indexes_mapping: 321\n        indexes_mapping: 375\n        indexes_mapping: 291\n        indexes_mapping: 185\n        indexes_mapping: 40\n        indexes_mapping: 39\n        indexes_mapping: 37\n        indexes_mapping: 0\n        indexes_mapping: 267\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 409\n        indexes_mapping: 78\n        indexes_mapping: 95\n        indexes_mapping: 88\n        indexes_mapping: 178\n        indexes_mapping: 87\n        indexes_mapping: 14\n        indexes_mapping: 317\n        indexes_mapping: 402\n        indexes_mapping: 318\n        indexes_mapping: 324\n        indexes_mapping: 308\n        indexes_mapping: 191\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 13\n        indexes_mapping: 312\n        indexes_mapping: 311\n        indexes_mapping: 310\n        indexes_mapping: 415\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 90\n        indexes_mapping: 180\n        indexes_mapping: 85\n        indexes_mapping: 16\n        indexes_mapping: 315\n        indexes_mapping: 404\n        indexes_mapping: 320\n        indexes_mapping: 307\n        indexes_mapping: 306\n        indexes_mapping: 184\n        indexes_mapping: 74\n        indexes_mapping: 73\n        indexes_mapping: 72\n        indexes_mapping: 11\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 408\n        indexes_mapping: 62\n        indexes_mapping: 96\n        indexes_mapping: 89\n        indexes_mapping: 179\n        indexes_mapping: 86\n        indexes_mapping: 15\n        indexes_mapping: 316\n        indexes_mapping: 403\n        indexes_mapping: 319\n        indexes_mapping: 325\n        indexes_mapping: 292\n        indexes_mapping: 183\n        indexes_mapping: 42\n        indexes_mapping: 41\n        indexes_mapping: 38\n        indexes_mapping: 12\n        indexes_mapping: 268\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 407\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 33\n        indexes_mapping: 7\n        indexes_mapping: 163\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 133\n        indexes_mapping: 246\n        indexes_mapping: 161\n        indexes_mapping: 160\n        indexes_mapping: 159\n        indexes_mapping: 158\n        indexes_mapping: 157\n        indexes_mapping: 173\n        indexes_mapping: 130\n        indexes_mapping: 25\n        indexes_mapping: 110\n        indexes_mapping: 24\n        indexes_mapping: 23\n        indexes_mapping: 22\n        indexes_mapping: 26\n        indexes_mapping: 112\n        indexes_mapping: 243\n        indexes_mapping: 247\n        indexes_mapping: 30\n        indexes_mapping: 29\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 56\n        indexes_mapping: 190\n        indexes_mapping: 226\n        indexes_mapping: 31\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 244\n        indexes_mapping: 113\n        indexes_mapping: 225\n        indexes_mapping: 224\n        indexes_mapping: 223\n        indexes_mapping: 222\n        indexes_mapping: 221\n        indexes_mapping: 189\n        indexes_mapping: 35\n        indexes_mapping: 124\n        indexes_mapping: 46\n        indexes_mapping: 53\n        indexes_mapping: 52\n        indexes_mapping: 65\n        indexes_mapping: 143\n        indexes_mapping: 111\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 128\n        indexes_mapping: 245\n        indexes_mapping: 156\n        indexes_mapping: 70\n        indexes_mapping: 63\n        indexes_mapping: 105\n        indexes_mapping: 66\n        indexes_mapping: 107\n        indexes_mapping: 55\n        indexes_mapping: 193\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 263\n        indexes_mapping: 249\n        indexes_mapping: 390\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 362\n        indexes_mapping: 466\n        indexes_mapping: 388\n        indexes_mapping: 387\n        indexes_mapping: 386\n        indexes_mapping: 385\n        indexes_mapping: 384\n        indexes_mapping: 398\n        indexes_mapping: 359\n        indexes_mapping: 255\n        indexes_mapping: 339\n        indexes_mapping: 254\n        indexes_mapping: 253\n        indexes_mapping: 252\n        indexes_mapping: 256\n        indexes_mapping: 341\n        indexes_mapping: 463\n        indexes_mapping: 467\n        indexes_mapping: 260\n        indexes_mapping: 259\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 286\n        indexes_mapping: 414\n        indexes_mapping: 446\n        indexes_mapping: 261\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 464\n        indexes_mapping: 342\n        indexes_mapping: 445\n        indexes_mapping: 444\n        indexes_mapping: 443\n        indexes_mapping: 442\n        indexes_mapping: 441\n        indexes_mapping: 413\n        indexes_mapping: 265\n        indexes_mapping: 353\n        indexes_mapping: 276\n        indexes_mapping: 283\n        indexes_mapping: 282\n        indexes_mapping: 295\n        indexes_mapping: 372\n        indexes_mapping: 340\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 357\n        indexes_mapping: 465\n        indexes_mapping: 383\n        indexes_mapping: 300\n        indexes_mapping: 293\n        indexes_mapping: 334\n        indexes_mapping: 296\n        indexes_mapping: 336\n        indexes_mapping: 285\n        indexes_mapping: 417\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 468\n        indexes_mapping: 469\n        indexes_mapping: 470\n        indexes_mapping: 471\n        indexes_mapping: 472\n        z_refinement {\n          assign_average {\n            indexes_for_average: 33\n            indexes_for_average: 7\n            indexes_for_average: 163\n            indexes_for_average: 144\n            indexes_for_average: 145\n            indexes_for_average: 153\n            indexes_for_average: 154\n            indexes_for_average: 155\n            indexes_for_average: 133\n            indexes_for_average: 246\n            indexes_for_average: 161\n            indexes_for_average: 160\n            indexes_for_average: 159\n            indexes_for_average: 158\n            indexes_for_average: 157\n            indexes_for_average: 173\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 473\n        indexes_mapping: 474\n        indexes_mapping: 475\n        indexes_mapping: 476\n        indexes_mapping: 477\n        z_refinement {\n          assign_average {\n            indexes_for_average: 263\n            indexes_for_average: 249\n            indexes_for_average: 390\n            indexes_for_average: 373\n            indexes_for_average: 374\n            indexes_for_average: 380\n            indexes_for_average: 381\n            indexes_for_average: 382\n            indexes_for_average: 362\n            indexes_for_average: 466\n            indexes_for_average: 388\n            indexes_for_average: 387\n            indexes_for_average: 386\n            indexes_for_average: 385\n            indexes_for_average: 384\n            indexes_for_average: 398\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  input_stream: \"C1__LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  output_stream: \"LANDMARKS:facelandmarkcpu__landmarks\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    ext {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__LandmarkProjectionCalculator\"\n  calculator: \"LandmarkProjectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:facelandmarkcpu__landmarks\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"NORM_LANDMARKS:face_landmarks\"\n}\nnode {\n  calculator: \"EndLoopNormalizedLandmarkListVectorCalculator\"\n  input_stream: \"ITEM:face_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:multi_face_landmarks\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__LandmarksToDetectionCalculator\"\n  calculator: \"LandmarksToDetectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:face_landmarks\"\n  output_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  options {\n    ext {\n      rotation_vector_start_keypoint_index: 33\n      rotation_vector_end_keypoint_index: 263\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"face_rect_from_landmarks\"\n  options {\n    ext {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_landmarks\"\n}\ninput_stream: \"IMAGE:image\"\noutput_stream: \"LANDMARKS:multi_face_landmarks\"\noutput_stream: \"DETECTIONS:face_detections\"\noutput_stream: \"ROIS_FROM_LANDMARKS:face_rects_from_landmarks\"\noutput_stream: \"ROIS_FROM_DETECTIONS:face_rects_from_detections\"\ninput_side_packet: \"NUM_FACES:num_faces\"\ninput_side_packet: \"USE_PREV_LANDMARKS:use_prev_landmarks\"\ninput_side_packet: \"WITH_ATTENTION:with_attention\"\nexecutor {\n}\ntype: \"FaceLandmarkFrontCpu\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from datetime import datetime, timedelta\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "print(\"1단계\")\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "def download_video_from_s3(bucket_name, video_name, local_path):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=\"\", aws_secret_access_key=\"\")\n",
    "    try:\n",
    "        s3.download_file(bucket_name, f\"{video_name}.mp4\", local_path)\n",
    "        print(f\"Video downloaded from S3 to {local_path}\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "    print(\"download_video_from_s3 끝\")\n",
    "def process_video(video_name):\n",
    "    # S3에서 동영상 다운로드\n",
    "    bucket_name = '3-example-video'\n",
    "    local_video_path = f\"./{video_name}.mp4\"\n",
    "    download_video_from_s3(bucket_name, video_name, local_video_path)\n",
    "    # 동영상 파일 열기\n",
    "    cap = cv2.VideoCapture(local_video_path)\n",
    "    # 총 프레임 수\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # 동영상이 정상적으로 열렸는지 확인\n",
    "    if not cap.isOpened():\n",
    "        print(f\"비디오 파일을 찾을 수 없습니다: {local_video_path}\")\n",
    "        return\n",
    "    print(\"데이터 추출 전\")   # 여기까지 무조건 됨\n",
    "    # mediapipe FaceMesh 인스턴스 생성\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False,\n",
    "                               max_num_faces=1,\n",
    "                               refine_landmarks=True,\n",
    "                               min_detection_confidence=0.5,\n",
    "                               min_tracking_confidence=0.85) as face_mesh:\n",
    "        frame_count_with_landmarks = 0\n",
    "        print(\"된건가\")\n",
    "        # 동영상 프레임을 순회하며 처리\n",
    "        while cap.isOpened():\n",
    "            # 동영상에서 프레임 읽기\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # BGR을 RGB로 변환\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # 얼굴 랜드마크 검출\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "            # print(\"얼굴 검출 중\")\n",
    "            # 얼굴 랜드마크를 프레임에 표시\n",
    "            if results.multi_face_landmarks:\n",
    "                frame_count_with_landmarks += 1\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                              landmark_drawing_spec=drawing_spec,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                              landmark_drawing_spec=drawing_spec,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                    mp_drawing.draw_landmarks(image=frame,\n",
    "                                              landmark_list=face_landmarks,\n",
    "                                              connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                                              landmark_drawing_spec=None,\n",
    "                                              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "        # 처리가 끝나면 리소스 해제\n",
    "        cap.release()\n",
    "    Detection = frame_count_with_landmarks / total_frames\n",
    "    N_Detection = 1 - Detection\n",
    "    # 결과 데이터 추가\n",
    "    data = {\n",
    "        \"Total_Frame\": total_frames,\n",
    "        \"Detection_Frame\": frame_count_with_landmarks,\n",
    "        \"Probability\": Detection,\n",
    "        \"No_Probability\": N_Detection,\n",
    "        \"Video_Name\": video_name\n",
    "    }\n",
    "    # 결과 데이터 저장\n",
    "    with open(f\"{video_name}.json\", 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "        print('json파일 생성')\n",
    "    try:\n",
    "        # AWS S3에 데이터 업로드\n",
    "        s3 = boto3.client('s3', aws_access_key_id=\"AKIAWZMQVI3Z537F5OOB\", aws_secret_access_key=\"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\")\n",
    "        s3.upload_file(f\"{video_name}.json\", bucket_name, f\"{video_name}.json\")\n",
    "        print(\"AWS S3에 데이터 업로드 완료\")\n",
    "    except Exception as e:\n",
    "        print(\"error occurred: \", str(e))\n",
    "    # 끝\n",
    "    print(\"데이터 삽입이 완료되었습니다.\")\n",
    "def get_latest_video_name(bucket_name):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=\"AKIAWZMQVI3Z537F5OOB\", aws_secret_access_key=\"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\")\n",
    "    # S3 버킷 내에서 객체 목록을 가져옴\n",
    "    response = s3.list_objects(Bucket=bucket_name)\n",
    "    # 가장 최근에 업로드된 객체 선택\n",
    "    latest_object = max(response['Contents'], key=lambda x: x['LastModified'])\n",
    "    # 파일 이름 반환 (확장자 제외)\n",
    "    latest_video_name = os.path.splitext(os.path.basename(latest_object['Key']))[0]\n",
    "    return latest_video_name\n",
    "if __name__ == '__main__':\n",
    "    # S3 버킷 이름\n",
    "    print(\"os.environ: \", os.environ)\n",
    "    s3_bucket_name = '3-example-video'\n",
    "    # 최근에 업로드된 동영상 이름 가져오기\n",
    "    latest_video_name = get_latest_video_name(s3_bucket_name)\n",
    "    print('latest_video_name : ', latest_video_name)\n",
    "    # 동영상 처리 함수 호출\n",
    "    process_video(latest_video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
